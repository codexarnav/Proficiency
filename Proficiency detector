import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow import keras
import matplotlib.pyplot as plt

# Load the dataset
df = pd.read_csv('quiz_proficiency_dataset.csv')

# Prepare the features and target
X = df[['current_proficiency', 'quiz_difficulty', 'quiz_score']]
y = df['new_proficiency']

# Encode quiz difficulty
difficulty_mapping = {'easy': 0, 'medium': 1, 'hard': 2}
X['quiz_difficulty'] = X['quiz_difficulty'].map(difficulty_mapping)

# Split the data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Scale the features
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Create the model
model = keras.Sequential([
    keras.layers.Dense(64, activation='relu', input_shape=(3,)),
    keras.layers.Dense(32, activation='relu'),
    keras.layers.Dense(16, activation='relu'),
    keras.layers.Dense(1)
])

# Compile the model
model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])

# Train the model
history = model.fit(X_train_scaled, y_train, epochs=200, batch_size=32, validation_split=0.2, verbose=1)

# Evaluate the model
test_loss, test_mae = model.evaluate(X_test_scaled, y_test, verbose=0)
print(f"\nTest Mean Absolute Error: {test_mae:.2f}")

# Function to predict new proficiency
def predict_proficiency(current_proficiency, quiz_difficulty, quiz_score):
    difficulty_numeric = difficulty_mapping[quiz_difficulty]
    input_data = np.array([[current_proficiency, difficulty_numeric, quiz_score]])
    input_scaled = scaler.transform(input_data)
    prediction = model.predict(input_scaled)[0][0]
    return np.clip(prediction, 0, 100)

# Example usage
current_proficiency = 70
quiz_difficulty = 'medium'
quiz_score = 80

new_proficiency = predict_proficiency(current_proficiency, quiz_difficulty, quiz_score)
print(f"\nPredicted new proficiency score: {new_proficiency:.2f}")

# Compare predictions with actual values
df['predicted_proficiency'] = df.apply(lambda row: predict_proficiency(
    row['current_proficiency'], row['quiz_difficulty'], row['quiz_score']), axis=1)

print("\nComparison of Actual vs Predicted Proficiency:")
print(df[['current_proficiency', 'quiz_difficulty', 'quiz_score', 'new_proficiency', 'predicted_proficiency']].head(10))

# Calculate Mean Absolute Error
mae = np.mean(np.abs(df['new_proficiency'] - df['predicted_proficiency']))
print(f"\nOverall Mean Absolute Error: {mae:.2f}")

# Visualize the model's performance
plt.figure(figsize=(10, 6))
plt.scatter(df['new_proficiency'], df['predicted_proficiency'], alpha=0.5)
plt.plot([0, 100], [0, 100], 'r--')
plt.xlabel('Actual New Proficiency')
plt.ylabel('Predicted New Proficiency')
plt.title('Actual vs Predicted Proficiency')
plt.show()

# Plot training history
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Mean Squared Error')
plt.title('Training and Validation Loss')
plt.legend()
plt.show()
